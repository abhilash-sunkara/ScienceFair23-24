{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp1f6LM/r7TRWPaHOdrWHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhilash-sunkara/ScienceFair23-24/blob/main/3dPrintingFailureDetectionV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYMaqWxI_Rls",
        "outputId": "b6ab3285-3ca3-44d2-88ba-4e4e417aff01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 1557 files belonging to 5 classes.\n",
            "Using 1246 files for training.\n",
            "Found 1557 files belonging to 5 classes.\n",
            "Using 311 files for validation.\n",
            "['Bed_No_Stick', 'Leg_Broken', 'No_Bottom', 'No_Defect', 'No_Support']\n",
            "(32, 180, 180, 3)\n",
            "(32,)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_3 (Rescaling)     (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 180, 180, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 90, 90, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 90, 90, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 45, 45, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 45, 45, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 22, 22, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 30976)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               3965056   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3989285 (15.22 MB)\n",
            "Trainable params: 3989285 (15.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "39/39 [==============================] - 77s 2s/step - loss: 0.6156 - accuracy: 0.7841 - val_loss: 0.0661 - val_accuracy: 0.9936\n",
            "Epoch 2/15\n",
            "39/39 [==============================] - 49s 1s/step - loss: 0.0268 - accuracy: 0.9960 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 3/15\n",
            "39/39 [==============================] - 50s 1s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9968\n",
            "Epoch 4/15\n",
            "39/39 [==============================] - 53s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 5/15\n",
            "39/39 [==============================] - 50s 1s/step - loss: 5.3734e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9968\n",
            "Epoch 6/15\n",
            "39/39 [==============================] - 51s 1s/step - loss: 1.9655e-04 - accuracy: 1.0000 - val_loss: 4.4976e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/15\n",
            "39/39 [==============================] - 53s 1s/step - loss: 1.1300e-04 - accuracy: 1.0000 - val_loss: 4.5447e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "39/39 [==============================] - 52s 1s/step - loss: 8.6835e-05 - accuracy: 1.0000 - val_loss: 3.6244e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "39/39 [==============================] - 56s 1s/step - loss: 7.0492e-05 - accuracy: 1.0000 - val_loss: 3.0496e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "39/39 [==============================] - 49s 1s/step - loss: 5.9560e-05 - accuracy: 1.0000 - val_loss: 3.1548e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "39/39 [==============================] - 51s 1s/step - loss: 5.0080e-05 - accuracy: 1.0000 - val_loss: 2.8320e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "39/39 [==============================] - 51s 1s/step - loss: 4.2349e-05 - accuracy: 1.0000 - val_loss: 2.6566e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "39/39 [==============================] - 51s 1s/step - loss: 3.7313e-05 - accuracy: 1.0000 - val_loss: 2.3323e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "39/39 [==============================] - 50s 1s/step - loss: 3.2141e-05 - accuracy: 1.0000 - val_loss: 2.1304e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "39/39 [==============================] - 51s 1s/step - loss: 2.8826e-05 - accuracy: 1.0000 - val_loss: 2.2522e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Datasets/DataSetV2/\"\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "#Splits total dataset into two categories for training and validation\n",
        "#Also detects different classes of the images, basically detecting categories of images\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  directory = data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  directory = data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "num_classes = len(class_names)\n",
        "\"\"\"\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "\"\"\"\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "epochs=15\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n",
        "\n",
        "#!ls \"/content/drive/MyDrive/Datasets/archive/defected\"\n",
        "\n"
      ]
    }
  ]
}